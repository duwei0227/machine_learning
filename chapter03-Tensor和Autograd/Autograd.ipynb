{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autograd.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duwei0227/machine_learning/blob/master/chapter03-Tensor%E5%92%8CAutograd/Autograd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txPWxnGlLSIm",
        "colab_type": "text"
      },
      "source": [
        "### AutoGrad\n",
        "能够根据输入和前向传播过程自动构建计算图，并执行反向传播"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDrQVm2ULwIl",
        "colab_type": "text"
      },
      "source": [
        "#### requires_grad\n",
        "autograd记录对tensor的操作记录用来构建计算图。   \n",
        "Variable提供了大部分tensor支持的函数，但不支持inplace函数，因这些函数会修改tensor本身；而在反向传播中，variable需要缓存原来的tensor来计算反向传播的梯度。如果要计算各个节点的梯度。只需要调用根节点的backward方法，autograd会自动沿着计算图反向传播，计算每一个叶子节点的梯度。  \n",
        "  \n",
        "    \n",
        "  variable.backward(gradient=None, retain_graph=None, create_graph=None)：\n",
        "  * grad_variables: 形状与variable一致，对于y.backward(),grad_variables相当于链式法则 $\\frac{dz}{dx} = \\frac{dz}{dy} * \\frac{dy}{dx}$ 中的$\\frac{dz}{dy}$  \n",
        "  grad_variables也可以是tensor或序列。\n",
        "  * retain_graph: 反向传播需要缓存一些结果，反向传播后，这些缓存会被清空，可通过指定这个参数不清空缓存，用来多次反向传播  \n",
        "  * create_graph：对反向传播过程再次构建计算图，可通过 backward of backward实现高阶求导"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0Q5wLEvLiiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA92OOV3nSef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 在创建tensor的时候指定 requires_grad\n",
        "a = torch.randn(3, 4, requires_grad=True)\n",
        "# 或者\n",
        "b = torch.randn(3, 4).requires_grad_()\n",
        "# 或者\n",
        "c = torch.randn(3, 4)\n",
        "c.requires_grad = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n7wLNLfnegO",
        "colab_type": "code",
        "outputId": "9280833b-db46-4b1b-f0dd-b2cb7dbf3a57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "a, b, c"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.7523,  2.1689, -1.2582, -1.3262],\n",
              "         [ 0.1519,  0.5212,  0.5778, -0.0766],\n",
              "         [ 0.2492, -0.4664, -1.9198, -0.2537]], requires_grad=True),\n",
              " tensor([[-0.5903, -0.1624, -0.4211, -1.1536],\n",
              "         [-0.8510,  0.7200, -2.5447,  1.7686],\n",
              "         [-0.0898,  0.4605, -0.3195, -0.9958]], requires_grad=True),\n",
              " tensor([[-1.8250, -0.0493,  2.7586,  0.7275],\n",
              "         [ 1.4920, -0.0932, -0.5842, -1.8870],\n",
              "         [ 0.5982,  2.0370,  0.5853,  0.0427]], requires_grad=True))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sDaKL56oCex",
        "colab_type": "code",
        "outputId": "587eae75-d255-44c7-c4f7-f8afadc15065",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "d = torch.zeros(3, 4, requires_grad=True)\n",
        "d"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhoRKZz8oNiI",
        "colab_type": "code",
        "outputId": "5904d6c5-1fcc-4ffc-9e0a-9983e0a6c1b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# e = a + d\n",
        "e = a.add(d)\n",
        "e"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.7523,  2.1689, -1.2582, -1.3262],\n",
              "        [ 0.1519,  0.5212,  0.5778, -0.0766],\n",
              "        [ 0.2492, -0.4664, -1.9198, -0.2537]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYMYBuwVoQaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = e.sum()\n",
        "f.backward()  # 反向传播"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20fHmuNRoaUk",
        "colab_type": "code",
        "outputId": "52fe073d-2eec-4d57-8bc8-d0491255cb1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "a.grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEybKS0JpARF",
        "colab_type": "text"
      },
      "source": [
        "#### 示例：\n",
        "计算下面这个函数的导函数：\n",
        "$$ y = x^2 * e^x$$\n",
        "它的导函数是：\n",
        "$$ \\frac{dy}{dx} = 2x * e^x + x^2 * e^x$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RM8zLpeAow90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f(x):\n",
        "  \"\"\"计算y\"\"\"\n",
        "  y = x ** 2 * torch.exp(x)\n",
        "  return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoYGqz4bpfwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gradf(x):\n",
        "  \"\"\"手动求导函数\"\"\"\n",
        "  dx = 2 * x * torch.exp(x) + x ** 2 * torch.exp(x)\n",
        "  return dx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aGAlDk-ppbc",
        "colab_type": "code",
        "outputId": "df591f65-14c8-44ac-b3dc-749470e2ab64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "x = torch.randn(3, 4, requires_grad=True)\n",
        "y = f(x)\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0254, 2.8214, 0.0041, 0.2447],\n",
              "        [0.0294, 0.0088, 0.8906, 2.2071],\n",
              "        [0.2332, 0.0055, 0.5210, 0.9136]], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBFvELWCpwI4",
        "colab_type": "code",
        "outputId": "900d6ee7-3f7b-40e4-c3a2-90284f6ecf9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "y.backward(torch.ones(y.size()))  # gradient形状与y一致\n",
        "x.grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2667,  8.3948,  0.1358, -0.4514],\n",
              "        [-0.2829, -0.1701,  3.5341,  6.9426],\n",
              "        [-0.4551,  0.1589, -0.1168,  3.5998]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W40WGtsrp94x",
        "colab_type": "code",
        "outputId": "5588e61f-47d7-405b-b49b-d7ab1eb7809a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "gradf(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2667,  8.3948,  0.1358, -0.4514],\n",
              "        [-0.2829, -0.1701,  3.5341,  6.9426],\n",
              "        [-0.4551,  0.1589, -0.1168,  3.5998]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzdhxqK5p_5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.ones(1)\n",
        "b = torch.rand(1, requires_grad=True)\n",
        "w = torch.rand(1, requires_grad=True)\n",
        "\n",
        "y = w * x\n",
        "z = y + b\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yekXLF3gqIxQ",
        "colab_type": "code",
        "outputId": "33f0b734-490f-4215-a993-b3fedd04529c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x.requires_grad, w.requires_grad, b.requires_grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(False, True, True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVyRLo1K61tt",
        "colab_type": "code",
        "outputId": "d1980a77-bd7d-4267-9bed-a229ca683c81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# y依赖于需要求导的w\n",
        "y.requires_grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExiZKnXW7iOl",
        "colab_type": "code",
        "outputId": "7548bdb2-7b0c-4190-de04-00ea86632a59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x.is_leaf, w.is_leaf, b.is_leaf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, True, True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM7SMT8G7pAt",
        "colab_type": "code",
        "outputId": "d024bec5-709a-470c-f2d7-4e61bb6f0746",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# grad_fn 可以查看这个variab的反向传播函数\n",
        "z.grad_fn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AddBackward0 at 0x7f540423db00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfm_O4HB8BsP",
        "colab_type": "code",
        "outputId": "80e91122-bbaa-4d73-dd06-dca5b8a4a16f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# next_functions保存grad_fn的输入，是一个tuple，tuple的元素也是Function\n",
        "# z = y + b = w * x + b\n",
        "z.grad_fn.next_functions"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((<MulBackward0 at 0x7f540423db38>, 0),\n",
              " (<AccumulateGrad at 0x7f540423d668>, 0))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ywr-Hs88uX8",
        "colab_type": "code",
        "outputId": "b636eba6-fa0f-44f7-b3aa-ac8ee0fdc09c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z.grad_fn.next_functions[0][0] == y.grad_fn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwNHXEoaCTU6",
        "colab_type": "code",
        "outputId": "adc1207b-665f-4516-84a2-77e91a5ad400",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.grad_fn.next_functions"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((<AccumulateGrad at 0x7f540423d7f0>, 0), (None, 0))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAJwXPZprWdv",
        "colab_type": "code",
        "outputId": "043855d5-e248-4967-cbc9-1971f6ab34d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 叶子节点的grad_fn是None\n",
        "w.grad_fn, b.grad_fn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5L0Nf_pNr9q7",
        "colab_type": "text"
      },
      "source": [
        "计算w的梯度时，需要用到x的数值(${\\partial y\\over \\partial w} = x $)，这些数值在前向传播过程中会保存成buffer，在计算完梯度后会自动清空。为了能够多次反向传播需要指定retain_graph来保留这些buffer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO6f7ztcr3Eh",
        "colab_type": "code",
        "outputId": "a187bf17-f011-46f7-e119-e4bac0ba513c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z.backward(retain_graph=True)\n",
        "w.grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxxQZYBzsb6Y",
        "colab_type": "code",
        "outputId": "8bae1005-ab3f-45ba-d90d-00e00b893961",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 多次反向传播，梯度累加，，这也就是w中AccumulateGrad标识的含义\n",
        "z.backward()\n",
        "w.grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeWFPajitS19",
        "colab_type": "text"
      },
      "source": [
        "Pytor使用的是动态图，它的计算在每次前向传播时都是从头开始构建，所以它能够使用python控制语句，根据需求创建计算图。图在运行时构建"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvLRvTLCso5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def abs(x):\n",
        "  if x.data[0] > 0: return x\n",
        "  else: return -x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VatnVJuFuOGl",
        "colab_type": "code",
        "outputId": "3b78c619-df30-49f6-8f11-c789472a2f25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.ones(1, requires_grad=True)\n",
        "y = abs(x)\n",
        "y.backward()\n",
        "x.grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK80wfFCuhoq",
        "colab_type": "code",
        "outputId": "02ddc8fd-071c-4b87-93a0-7cad224ddf9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = -1 * torch.ones(1)\n",
        "x = x.requires_grad_()\n",
        "y = abs(x)\n",
        "y.backward()\n",
        "x.grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVMJ2njPwMMG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f(x):\n",
        "  result = 1\n",
        "  for ii in x:\n",
        "    if ii.item() > 0:\n",
        "      result *= ii\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n09nBaEL0W4U",
        "colab_type": "code",
        "outputId": "4f403975-de15-41ee-d7b0-e390223d983f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x = torch.arange(-2, 4, requires_grad=True, dtype=torch.float32)\n",
        "y = f(x)\n",
        "x, y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-2., -1.,  0.,  1.,  2.,  3.], requires_grad=True),\n",
              " tensor(6., grad_fn=<MulBackward0>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBjZ5PeJ0eXy",
        "colab_type": "code",
        "outputId": "48e7cf9f-c630-4e15-e69f-cc5aa8725a0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.backward()\n",
        "x.grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 6., 3., 2.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfyPqNdm00Ko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.ones(1, requires_grad=True, dtype=torch.float32)\n",
        "w = torch.rand(1, requires_grad=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLxslWOC1HRH",
        "colab_type": "code",
        "outputId": "5ce226e4-3cc6-4591-9f40-cf081a6940fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y = x * w\n",
        "# y依赖于w， 而w.requires_grad=True\n",
        "x.requires_grad, w.requires_grad, y.requires_grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, True, True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foQz1RXl1RVN",
        "colab_type": "code",
        "outputId": "09b42940-e038-4a71-d989-bd6fbbbcdbae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with torch.no_grad():\n",
        "  x = torch.ones(1)\n",
        "  w = torch.rand(1, requires_grad=True)\n",
        "  y = x * w\n",
        "# y依赖于w和x，虽然w.requires_grad = True，但是y的requires_grad依旧为False\n",
        "x.requires_grad, w.requires_grad, y.requires_grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(False, True, False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPi13Kvl1nPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#torch.set_grad_enabled(True)  # 设置默认配置"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89uUBRX62F9o",
        "colab_type": "text"
      },
      "source": [
        "如果我们想要修改tensor的值，但是又不希望被autograd记录，那么我们可以对tensor.data进行操作"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QsM6m1O1zb0",
        "colab_type": "code",
        "outputId": "4159e846-9763-46e5-c28a-5dc9f7bf1442",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "a = torch.ones(3, 4, requires_grad=True, dtype=torch.float32)\n",
        "b = torch.ones(3, 4, requires_grad=True, dtype=torch.float32)\n",
        "c = a * b\n",
        "a.data\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYo5wxSg2T07",
        "colab_type": "code",
        "outputId": "068f6434-4756-4c94-f70d-878ea5cc5d55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a.data.requires_grad # 已经独立于计算图之外"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VeB1oO_2XkR",
        "colab_type": "code",
        "outputId": "7db33a36-dd5d-4f34-b8d7-fc9c977c2e2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a.requires_grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEcBZ4Fn2d7Z",
        "colab_type": "code",
        "outputId": "5fcba794-10d0-444b-a8f5-bedfccf780c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "d = a.data.sigmoid_() \n",
        "d.requires_grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnLXkdrQ2ls0",
        "colab_type": "code",
        "outputId": "660f30ae-a892-4237-c80c-4daa4892b72d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7311, 0.7311, 0.7311, 0.7311],\n",
              "        [0.7311, 0.7311, 0.7311, 0.7311],\n",
              "        [0.7311, 0.7311, 0.7311, 0.7311]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTIkGpjZ3bDr",
        "colab_type": "text"
      },
      "source": [
        "### 扩展autograd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yjXkIWy2rhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import Function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxlZ4SQE3v9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Mul(Function):\n",
        "  @staticmethod\n",
        "  def forward(ctx, w, x, b, x_requires_grad=True):\n",
        "    ctx.x_requires_grad = x_requires_grad\n",
        "    ctx.save_for_backward(w, x)\n",
        "    output = w * x + b\n",
        "    return output\n",
        "  \n",
        "  @staticmethod\n",
        "  def backward(ctx, grad_output):\n",
        "    w, x = ctx.saved_tensors\n",
        "    grad_w = grad_output * x\n",
        "    if ctx.x_requires_grad:\n",
        "      grad_x = grad_output * x\n",
        "    else:\n",
        "      grad_x = None\n",
        "      \n",
        "    grad_b = grad_output * 1\n",
        "    return grad_w, grad_x, grad_b, None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sE20h0i4fyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}